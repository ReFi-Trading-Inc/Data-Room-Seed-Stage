# IP & Proprietary Technology

ReFi.Trading develops proprietary reinforcement learning models tailored to algorithmic trading. The models use Proximal Policy Optimisation (PPO) and Double Deep Q‑Network (DDQN) algorithms with custom reward shaping and risk‑aware loss functions. Model artefacts are stored securely in Google Cloud Storage and anchored on‑chain in Phase 3. The company may seek patent protection for its RL architecture and non‑custodial execution framework. Trade secrets include hyperparameter schedules, feature engineering methods and safety heuristics. The long‑term strategy balances open‑sourcing certain components to build community trust while retaining key competitive advantages.

## A USPTO Patent has already been filed Patent #63/827,802 ’SYSTEM AND METHOD FOR NON‑CUSTODIAL, ZERO‑KNOWLEDGE‑VERIFIED REINFORCEMENT‑LEARNING TRADING'
## Abstract
An automated electronic trading platform couples reinforcement-learning agents with pre-trade zero-knowledge risk verification executed on a decentralised infrastructure mesh. Real-time market data are ingested, an agent engine proposes a trade action, and a zero-knowledge proof generator attests that the action satisfies a user-defined value-at-risk limit. A self-custodial smart-contract wallet signs only those actions accompanied by a valid proof, thereby preserving user custody while providing cryptographic assurance of risk compliance. Infrastructure nodes stake a native token and are rewarded or penalised according to service-level objectives monitored by a quality-of-service oracle. Recursive aggregation techniques accelerate proof verification, permitting execution latency within institutional thresholds. The system further records immutable audit artefacts, enabling transparent post-trade forensics. The disclosed architecture delivers verifiable, low-latency trading without central custody.
